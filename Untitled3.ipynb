{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOIdtPUfitQeiICNnDr82FO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ujjawal1709/PPT-Maker/blob/main/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lwTKTAYi-UJ"
      },
      "outputs": [],
      "source": [
        "# Install necessary libraries\n",
        "!pip install transformers\n",
        "!pip install python-docx\n",
        "!pip install python-pptx\n",
        "!pip install sentencepiece\n",
        "\n",
        "from google.colab import files\n",
        "from docx import Document\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from pptx import Presentation\n",
        "\n",
        "# Function to extract text from DOCX file\n",
        "def extract_text_from_docx(docx_path):\n",
        "    doc = Document(docx_path)\n",
        "    full_text = []\n",
        "    for para in doc.paragraphs:\n",
        "        full_text.append(para.text)\n",
        "    return '\\n'.join(full_text)\n",
        "\n",
        "# Function to summarize text using DistilBART\n",
        "def summarize_text(text, model, tokenizer, max_chunk_length=2048, max_summary_length=300, min_summary_length=80):\n",
        "    # Break the text into chunks if necessary\n",
        "    chunks = [text[i:i+max_chunk_length] for i in range(0, len(text), max_chunk_length)]\n",
        "\n",
        "    summaries = []\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        print(f\"Processing chunk {i+1}/{len(chunks)}...\")\n",
        "        inputs = tokenizer.encode(\"summarize: \" + chunk, return_tensors=\"pt\", max_length=max_chunk_length, truncation=True)\n",
        "        summary_ids = model.generate(inputs, max_length=max_summary_length, min_length=min_summary_length, length_penalty=2.0, num_beams=2, early_stopping=True)\n",
        "        summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "        summaries.append(summary)\n",
        "        print(f\"Chunk {i+1} processed.\")\n",
        "\n",
        "    return ' '.join(summaries)\n",
        "\n",
        "# Function to split summarized text into slides\n",
        "def split_into_slides(summary, max_words_per_slide=50):\n",
        "    words = summary.split()\n",
        "    slides = [' '.join(words[i:i+max_words_per_slide]) for i in range(0, len(words), max_words_per_slide)]\n",
        "    return slides\n",
        "\n",
        "# Improved function to generate slide titles based on content analysis\n",
        "def generate_slide_titles(slides):\n",
        "    titles = []\n",
        "    for slide in slides:\n",
        "        sentences = slide.split('. ')\n",
        "        if sentences:\n",
        "            longest_sentence = max(sentences, key=len).strip()\n",
        "            if len(longest_sentence) > 50:\n",
        "                title_candidate = ' '.join(longest_sentence.split()[:8]) + '...'\n",
        "            else:\n",
        "                title_candidate = longest_sentence\n",
        "            titles.append(title_candidate)\n",
        "        else:\n",
        "            titles.append(\"Untitled Slide\")\n",
        "    return titles\n",
        "\n",
        "# Function to create PowerPoint from summarized text\n",
        "def create_ppt(slides_data, titles, ppt_path='output_presentation.pptx'):\n",
        "    prs = Presentation()\n",
        "\n",
        "    for i, slide_data in enumerate(slides_data):\n",
        "        slide_layout = prs.slide_layouts[1]  # Title and Content layout\n",
        "        slide = prs.slides.add_slide(slide_layout)\n",
        "\n",
        "        title = slide.shapes.title\n",
        "        content = slide.placeholders[1].text_frame\n",
        "\n",
        "        # Set slide title from generated titles\n",
        "        slide_title = titles[i]\n",
        "        title.text = slide_title\n",
        "\n",
        "        # Add summarized points as bullet points\n",
        "        paragraphs = slide_data.split('. ')\n",
        "        for point in paragraphs:\n",
        "            point = point.strip()  # Remove leading/trailing spaces\n",
        "            if not point.endswith('.'):  # Ensure proper punctuation\n",
        "                point += '.'\n",
        "            p = content.add_paragraph()\n",
        "            p.text = point\n",
        "\n",
        "    prs.save(ppt_path)\n",
        "\n",
        "# Main function to convert document to summarized PowerPoint presentation\n",
        "def document_to_ppt(docx_path, ppt_output_path):\n",
        "    try:\n",
        "        # Step 1: Extract text from DOCX\n",
        "        print(\"Extracting text from document...\")\n",
        "        full_text = extract_text_from_docx(docx_path)\n",
        "\n",
        "        # Step 2: Initialize summarization model and tokenizer\n",
        "        print(\"Loading summarization model...\")\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\"sshleifer/distilbart-cnn-12-6\")\n",
        "        model = AutoModelForSeq2SeqLM.from_pretrained(\"sshleifer/distilbart-cnn-12-6\")\n",
        "\n",
        "        # Step 3: Summarize text\n",
        "        print(\"Summarizing the text...\")\n",
        "        summarized_text = summarize_text(full_text, model, tokenizer)\n",
        "\n",
        "        # Step 4: Split summary into slides\n",
        "        print(\"Splitting summary into slide sections...\")\n",
        "        slides_data = split_into_slides(summarized_text)\n",
        "\n",
        "        # Step 5: Generate titles for slides\n",
        "        print(\"Generating titles for slides...\")\n",
        "        titles = generate_slide_titles(slides_data)\n",
        "\n",
        "        # Step 6: Create PowerPoint\n",
        "        print(f\"Generating PowerPoint presentation at {ppt_output_path}...\")\n",
        "        create_ppt(slides_data, titles, ppt_output_path)\n",
        "\n",
        "        print(\"PowerPoint presentation created successfully!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Run the converter\n",
        "if __name__ == \"__main__\":\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    # Ensure the uploaded file is handled correctly\n",
        "    docx_path = next(iter(uploaded.keys()))\n",
        "\n",
        "    if not docx_path.endswith('.docx'):\n",
        "        raise ValueError(\"Uploaded file is not a DOCX file. Please upload a valid DOCX file.\")\n",
        "\n",
        "    # Output PPTX file\n",
        "    ppt_output_path = 'output_presentation.pptx'\n",
        "\n",
        "    # Convert document to PowerPoint\n",
        "    document_to_ppt(docx_path, ppt_output_path)\n",
        "\n",
        "    # Download the output PowerPoint file\n",
        "    files.download(ppt_output_path)\n",
        "# Install necessary libraries\n",
        "!pip install transformers\n",
        "!pip install python-docx\n",
        "!pip install python-pptx\n",
        "!pip install sentencepiece\n",
        "\n",
        "from google.colab import files\n",
        "from docx import Document\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from pptx import Presentation\n",
        "\n",
        "# Function to extract text from DOCX file\n",
        "def extract_text_from_docx(docx_path):\n",
        "    doc = Document(docx_path)\n",
        "    full_text = []\n",
        "    for para in doc.paragraphs:\n",
        "        full_text.append(para.text)\n",
        "    return '\\n'.join(full_text)\n",
        "\n",
        "# Function to summarize text using DistilBART\n",
        "def summarize_text(text, model, tokenizer, max_chunk_length=2048, max_summary_length=300, min_summary_length=80):\n",
        "    # Break the text into chunks if necessary\n",
        "    chunks = [text[i:i+max_chunk_length] for i in range(0, len(text), max_chunk_length)]\n",
        "\n",
        "    summaries = []\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        print(f\"Processing chunk {i+1}/{len(chunks)}...\")\n",
        "        inputs = tokenizer.encode(\"summarize: \" + chunk, return_tensors=\"pt\", max_length=max_chunk_length, truncation=True)\n",
        "        summary_ids = model.generate(inputs, max_length=max_summary_length, min_length=min_summary_length, length_penalty=2.0, num_beams=2, early_stopping=True)\n",
        "        summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "        summaries.append(summary)\n",
        "        print(f\"Chunk {i+1} processed.\")\n",
        "\n",
        "    return ' '.join(summaries)\n",
        "\n",
        "# Function to split summarized text into slides\n",
        "def split_into_slides(summary, max_words_per_slide=50):\n",
        "    words = summary.split()\n",
        "    slides = [' '.join(words[i:i+max_words_per_slide]) for i in range(0, len(words), max_words_per_slide)]\n",
        "    return slides\n",
        "\n",
        "# Improved function to generate slide titles based on content analysis\n",
        "def generate_slide_titles(slides):\n",
        "    titles = []\n",
        "    for slide in slides:\n",
        "        sentences = slide.split('. ')\n",
        "        if sentences:\n",
        "            longest_sentence = max(sentences, key=len).strip()\n",
        "            if len(longest_sentence) > 50:\n",
        "                title_candidate = ' '.join(longest_sentence.split()[:8]) + '...'\n",
        "            else:\n",
        "                title_candidate = longest_sentence\n",
        "            titles.append(title_candidate)\n",
        "        else:\n",
        "            titles.append(\"Untitled Slide\")\n",
        "    return titles\n",
        "\n",
        "# Function to create PowerPoint from summarized text\n",
        "def create_ppt(slides_data, titles, ppt_path='output_presentation.pptx'):\n",
        "    prs = Presentation()\n",
        "\n",
        "    for i, slide_data in enumerate(slides_data):\n",
        "        slide_layout = prs.slide_layouts[1]  # Title and Content layout\n",
        "        slide = prs.slides.add_slide(slide_layout)\n",
        "\n",
        "        title = slide.shapes.title\n",
        "        content = slide.placeholders[1].text_frame\n",
        "\n",
        "        # Set slide title from generated titles\n",
        "        slide_title = titles[i]\n",
        "        title.text = slide_title\n",
        "\n",
        "        # Add summarized points as bullet points\n",
        "        paragraphs = slide_data.split('. ')\n",
        "        for point in paragraphs:\n",
        "            point = point.strip()  # Remove leading/trailing spaces\n",
        "            if not point.endswith('.'):  # Ensure proper punctuation\n",
        "                point += '.'\n",
        "            p = content.add_paragraph()\n",
        "            p.text = point\n",
        "\n",
        "    prs.save(ppt_path)\n",
        "\n",
        "# Main function to convert document to summarized PowerPoint presentation\n",
        "def document_to_ppt(docx_path, ppt_output_path):\n",
        "    try:\n",
        "        # Step 1: Extract text from DOCX\n",
        "        print(\"Extracting text from document...\")\n",
        "        full_text = extract_text_from_docx(docx_path)\n",
        "\n",
        "        # Step 2: Initialize summarization model and tokenizer\n",
        "        print(\"Loading summarization model...\")\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\"sshleifer/distilbart-cnn-12-6\")\n",
        "        model = AutoModelForSeq2SeqLM.from_pretrained(\"sshleifer/distilbart-cnn-12-6\")\n",
        "\n",
        "        # Step 3: Summarize text\n",
        "        print(\"Summarizing the text...\")\n",
        "        summarized_text = summarize_text(full_text, model, tokenizer)\n",
        "\n",
        "        # Step 4: Split summary into slides\n",
        "        print(\"Splitting summary into slide sections...\")\n",
        "        slides_data = split_into_slides(summarized_text)\n",
        "\n",
        "        # Step 5: Generate titles for slides\n",
        "        print(\"Generating titles for slides...\")\n",
        "        titles = generate_slide_titles(slides_data)\n",
        "\n",
        "        # Step 6: Create PowerPoint\n",
        "        print(f\"Generating PowerPoint presentation at {ppt_output_path}...\")\n",
        "        create_ppt(slides_data, titles, ppt_output_path)\n",
        "\n",
        "        print(\"PowerPoint presentation created successfully!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Run the converter\n",
        "if __name__ == \"__main__\":\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    # Ensure the uploaded file is handled correctly\n",
        "    docx_path = next(iter(uploaded.keys()))\n",
        "\n",
        "    if not docx_path.endswith('.docx'):\n",
        "        raise ValueError(\"Uploaded file is not a DOCX file. Please upload a valid DOCX file.\")\n",
        "\n",
        "    # Output PPTX file\n",
        "    ppt_output_path = 'output_presentation.pptx'\n",
        "\n",
        "    # Convert document to PowerPoint\n",
        "    document_to_ppt(docx_path, ppt_output_path)\n",
        "\n",
        "    # Download the output PowerPoint file\n",
        "    files.download(ppt_output_path)\n"
      ]
    }
  ]
}